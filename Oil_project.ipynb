{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно решить, где бурить новую скважину.\n",
    "\n",
    "Предоставлены пробы нефти в трёх регионах: в каждом 10 000 месторождений, где измерили качество нефти и объём её запасов. Постройте модель машинного обучения, которая поможет определить регион, где добыча принесёт наибольшую прибыль. Нужно проанализировать возможную прибыль и риски техникой *Bootstrap.*\n",
    "\n",
    "Шаги для выбора локации:\n",
    "\n",
    "- В избранном регионе ищут месторождения, для каждого определяют значения признаков;\n",
    "- Строят модель и оценивают объём запасов;\n",
    "- Выбирают месторождения с самым высокими оценками значений. Количество месторождений зависит от бюджета компании и стоимости разработки одной скважины;\n",
    "- Прибыль равна суммарной прибыли отобранных месторождений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from scipy import stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном это я добавляю необходимые библиотеки,который в дальнейшем потребуются для реализации проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 5)\n"
     ]
    }
   ],
   "source": [
    "data_0 = pd.read_csv('/datasets/geo_data_0.csv')\n",
    "data_0 = data_0.drop_duplicates().reset_index(drop = True)\n",
    "print(data_0.shape)\n",
    "#data_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь я делаю вычитку из 1 файла и смотрю на размеры таблицы и удаляю дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 5)\n"
     ]
    }
   ],
   "source": [
    "data_1 = pd.read_csv('/datasets/geo_data_1.csv')\n",
    "data_1 = data_1.drop_duplicates().reset_index(drop = True)\n",
    "print(data_1.shape)\n",
    "#data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь я делаю вычитку из 2 файла и смотрю на размеры таблицы и удаляю дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id         0\n",
      "f0         0\n",
      "f1         0\n",
      "f2         0\n",
      "product    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_2 = pd.read_csv('/datasets/geo_data_2.csv')\n",
    "data_2 = data_2.drop_duplicates().reset_index(drop = True)\n",
    "print(data_2.isna().sum())\n",
    "#data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь я делаю вычитку из 3 файла и смотрю на размеры таблицы и удаляю дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 3)\n",
      "(25000, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train_0, df_valid_0 = train_test_split(data_0, test_size = 0.25, random_state=12345)\n",
    "\n",
    "features_train_0 = df_train_0.drop(['product', 'id'], axis=1)\n",
    "target_train_0 = df_train_0['product']\n",
    "features_valid_0 = df_valid_0.drop(['product', 'id'], axis=1)\n",
    "target_valid_0 = df_valid_0['product']\n",
    "\n",
    "print(features_train_0.shape)\n",
    "print(features_valid_0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе я разбиваю на валидационную и тренеровочные выборки данных первого региона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 3)\n",
      "(25000, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train_1, df_valid_1 = train_test_split(data_1, test_size = 0.25, random_state=12345)\n",
    "\n",
    "features_train_1 = df_train_1.drop(['product', 'id'], axis=1)\n",
    "target_train_1 = df_train_1['product']\n",
    "features_valid_1 = df_valid_1.drop(['product', 'id'], axis=1)\n",
    "target_valid_1 = df_valid_1['product']\n",
    "\n",
    "print(features_train_1.shape)\n",
    "print(features_valid_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе я разбиваю на валидационную и тренеровочные выборки данных второго региона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 3)\n",
      "(25000, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train_2, df_valid_2 = train_test_split(data_2, test_size = 0.25, random_state=12345)\n",
    "\n",
    "features_train_2 = df_train_2.drop(['product', 'id'], axis=1)\n",
    "target_train_2 = df_train_2['product']\n",
    "features_valid_2 = df_valid_2.drop(['product', 'id'], axis=1)\n",
    "target_valid_2 = df_valid_2['product']\n",
    "\n",
    "print(features_train_2.shape)\n",
    "print(features_valid_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе я разбиваю на валидационную и тренеровочные выборки данных третьего региона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение и проверка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE =  37.5794217150813\n",
      "Средний запас сырья:  92.07859674082927\n"
     ]
    }
   ],
   "source": [
    "model_0 = LinearRegression()\n",
    "model_0.fit(features_train_0, target_train_0)\n",
    "valid_predicted_0 = model_0.predict(features_valid_0)\n",
    "answer_0 = valid_predicted_0\n",
    "answer_0 = pd.Series(answer_0)\n",
    "\n",
    "rmse_0 = mean_squared_error(target_valid_0, valid_predicted_0) ** 0.5\n",
    "print('RMSE = ', rmse_0)\n",
    "print('Средний запас сырья: ', target_valid_0.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE =  0.893099286775616\n",
      "Средний запас сырья:  68.72313602435997\n"
     ]
    }
   ],
   "source": [
    "model_1 = LinearRegression()\n",
    "model_1.fit(features_train_1, target_train_1)\n",
    "valid_predicted_1 = model_1.predict(features_valid_1)\n",
    "\n",
    "answer_1 = valid_predicted_1\n",
    "answer_1 = pd.Series(answer_1)\n",
    "\n",
    "rmse_1 = mean_squared_error(target_valid_1, valid_predicted_1) ** 0.5\n",
    "print('RMSE = ', rmse_1)\n",
    "print('Средний запас сырья: ', target_valid_1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE =  40.02970873393434\n",
      "Средний запас сырья:  94.88423280885438\n"
     ]
    }
   ],
   "source": [
    "model_2 = LinearRegression()\n",
    "model_2.fit(features_train_2, target_train_2)\n",
    "valid_predicted_2 = model_2.predict(features_valid_2)\n",
    "\n",
    "answer_2 = valid_predicted_2\n",
    "answer_2 = pd.Series(answer_2)\n",
    "\n",
    "rmse_2 = mean_squared_error(target_valid_2, valid_predicted_2) ** 0.5\n",
    "print('RMSE = ', rmse_2)\n",
    "print('Средний запас сырья: ', target_valid_2.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе я обучил модель линейной регрессии на тренеровочных выборках данных и вывожу на экран значение RMSE и среднего запаса сырья для каждого региона. Лучший результат получился у третьего региона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Подготовка к расчёту прибыли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Минимальный обьем сырья для одного месторождения, чтобы оно было без убытка: 111.11111111111111\n"
     ]
    }
   ],
   "source": [
    "min_product = 50000 / 450 \n",
    "print('Минимальный обьем сырья для одного месторождения, чтобы оно было без убытка:', min_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revenue(target, probabilities, count):\n",
    "    probs_sorted = probabilities.sort_values(ascending=False)\n",
    "    selected = target[probs_sorted.index][:count]\n",
    "    profit_per_region = selected.sum() * 1000 * 450 - 10000000000\n",
    "    return profit_per_region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь я нашел минимальный обьем сырья для одного безубыточного месторождения и написал функцию для расчета прибыли"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Расчёт прибыли и рисков "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/series.py:1143: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя выручка: -1727074054.4160826\n",
      "95%-ый доверительный интервал: (-1745083898.5071185, -1709064210.3250468)\n",
      "1%-квантиль: -2411688723.365426\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state = np.random.RandomState(12345)\n",
    "    \n",
    "values_0 = []\n",
    "for i in range(1000):\n",
    "    target_subsample = target_valid_0.sample(n=500, replace=True, random_state=state)\n",
    "    probs_subsample = answer_0[target_subsample.index]\n",
    "    \n",
    "    values_0.append(revenue(target_subsample, probs_subsample, 200))\n",
    "\n",
    "values_0 = pd.Series(values_0)\n",
    "lower_0 = values_0.quantile(0.01)\n",
    "\n",
    "mean_0 = values_0.mean()\n",
    "\n",
    "confidence_interval_0 = st.t.interval(0.95, len(values_0)-1, values_0.mean(), values_0.sem())\n",
    "\n",
    "print(\"Средняя выручка:\", mean_0)\n",
    "\n",
    "print(\"95%-ый доверительный интервал:\", confidence_interval_0)\n",
    "\n",
    "print(\"1%-квантиль:\", lower_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя выручка: -3811514804.935981\n",
      "95%-ый доверительный интервал: (-3829893845.280592, -3793135764.5913696)\n",
      "1%-квантиль: -4455315297.549019\n"
     ]
    }
   ],
   "source": [
    "values_1 = []\n",
    "for i in range(1000):\n",
    "    target_subsample = target_valid_1.sample(n=500, replace=True, random_state=state)\n",
    "    probs_subsample = answer_1[target_subsample.index]\n",
    "    \n",
    "    values_1.append(revenue(target_subsample, probs_subsample, 200))\n",
    "\n",
    "values_1 = pd.Series(values_1)\n",
    "lower_1 = values_1.quantile(0.01)\n",
    "\n",
    "mean_1 = values_1.mean()\n",
    "\n",
    "confidence_interval_1 = st.t.interval(0.95, len(values_1)-1, values_1.mean(), values_1.sem())\n",
    "\n",
    "print(\"Средняя выручка:\", mean_1)\n",
    "\n",
    "print(\"95%-ый доверительный интервал:\", confidence_interval_1)\n",
    "\n",
    "print(\"1%-квантиль:\", lower_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя выручка: -1480417773.5426087\n",
      "95%-ый доверительный интервал: (-1498850856.8746321, -1461984690.2105854)\n",
      "1%-квантиль: -2198850037.904337\n"
     ]
    }
   ],
   "source": [
    "values_2 = []\n",
    "for i in range(1000):\n",
    "    target_subsample = target_valid_2.sample(n=500, replace=True, random_state=state)\n",
    "    probs_subsample = answer_2[target_subsample.index]\n",
    "    \n",
    "    values_2.append(revenue(target_subsample, probs_subsample, 200))\n",
    "\n",
    "values_2 = pd.Series(values_2)\n",
    "lower_2 = values_2.quantile(0.01)\n",
    "\n",
    "mean_2 = values_2.mean()\n",
    "\n",
    "confidence_interval_2 = st.t.interval(0.95, len(values_2)-1, values_2.mean(), values_2.sem())\n",
    "\n",
    "print(\"Средняя выручка:\", mean_2)\n",
    "\n",
    "print(\"95%-ый доверительный интервал:\", confidence_interval_2)\n",
    "\n",
    "print(\"1%-квантиль:\", lower_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе я находил значения средней выручки, доверительного интервала и наиболее вероятный доход для каждого региона. Таким образом, на основании полученных показателей, можно сказать, что наиболее выгодный регион из трех является третий регион, поскольку значения показателей в данном регионе наиболее эффективные значения показателей по сравнению с другими и это говорит о том, что вероятнее всего наибольший доход компания получит в третьем регионе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
